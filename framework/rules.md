# Canonical Rules

**This is the single source of truth. All other files reference these rules. Do not duplicate.**

---

## Source Attribution

| Rule | Details |
|------|---------|
| Format | `[S001]`, `[S002]`, `[S003]`... |
| Append-only | Never renumber, never delete source IDs |
| Inline citation | `"The CEO knew by January [S001] [S002]."` |
| AI research | Goes to `research-leads/` — these are LEADS, not citable sources |
| Primary sources | Find the actual URL, capture evidence, then cite |

---

## Evidence Capture

| Rule | Details |
|------|---------|
| Capture immediately | When you find a source URL, capture it before moving on |
| Script usage | `./scripts/capture S001 https://example.com` |
| Document download | `./scripts/capture --document S015 https://sec.gov/filing.pdf` |
| Verify in evidence | Before citing, confirm claim exists in captured HTML/PDF |
| No source without evidence | Every `[SXXX]` must have files in `evidence/` |

---

## State Update Ownership

Only one agent updates each field to prevent race conditions:

| Field | Updated By |
|-------|------------|
| `current_phase` | Each agent sets at phase start |
| `current_iteration` | Synthesis Agent only |
| `next_source_id` | Investigation Agent (read-increment-write atomically) |
| `verification_passed` | Verification Agent only |
| `adversarial_complete` | Adversarial Agent only |
| `rigor_checkpoint_passed` | Rigor Checkpoint Agent only |
| `quality_checks_passed` | Quality Check Agent only |

---

## File Ownership

| File | Written By |
|------|------------|
| `research-leads/*.md` | Research Agents |
| `_extraction.json` | Extraction Agent (overwrites each iteration) |
| `_tasks.json` | Task Generation Agent, Adversarial Agent, Rigor Checkpoint Agent |
| `_coverage.json` | Coverage Agent (overwrites after each task batch) |
| `people.md`, `timeline.md`, `organizations.md` | Investigation Agents |
| `fact-check.md`, `statements.md`, `theories.md` | Investigation Agents |
| `positions.md` | Investigation Agents |
| `sources.md` | Investigation Agents (append new sources) |
| `summary.md` | Synthesis Agent (complete rewrite each time) |
| `iterations.md` | All agents (append checkpoints/logs) |
| `_state.json` | Per field ownership above |

---

## Task File Rules

### _tasks.json Structure

```json
{
  "tasks": [...],           // Main investigation tasks
  "adversarial_tasks": [...], // Counter-tasks from adversarial pass
  "rigor_gap_tasks": [...]   // Tasks generated by rigor checkpoint
}
```

### Task States

| State | Meaning |
|-------|---------|
| `pending` | Not yet started |
| `in_progress` | Agent working on it |
| `completed` | Done, findings in `findings_file` |

### Task Generation Rules

1. Every cycle MUST address 10 required perspectives (or explain N/A)
2. Every cycle MUST generate at least 2 curiosity tasks
3. Tasks must have: id, description, perspective, priority, rationale, approach, success_criteria
4. Flag any perspective with no applicable task

---

## Coverage Metrics Rules

### Required Thresholds (for termination)

| Metric | Threshold |
|--------|-----------|
| People: investigated/mentioned | ≥ 90% |
| Entities: investigated/mentioned | ≥ 90% |
| Claims: verified/total | ≥ 80% |
| Sources: captured/cited | = 100% |
| Positions: documented/identified | = 100% |
| Contradictions: explored/identified | = 100% |

### Coverage Agent Updates _coverage.json After:

- Every task batch completion
- Before termination gate check

---

## Verification Rules

**Core checklist (all must be YES):**
1. All major people investigated
2. All major claims fact-checked (from ALL positions)
3. All positions steelmanned
4. Alternative theories addressed with evidence
5. All sources have captured evidence
6. No contradicted claims in evidence check

**Anti-Hallucination Check:**
```bash
node scripts/verify-claims.js cases/[case-id]
```

| Verdict | Action |
|---------|--------|
| VERIFIED | None |
| NOT_FOUND | Find evidence or revise claim |
| CONTRADICTED | Urgent fix required |
| NO_EVIDENCE | Capture the source |

---

## Termination Gates (8 Required)

**ALL must be true to terminate:**

```
1. Coverage thresholds met (see above)
2. No HIGH priority tasks pending
3. adversarial_complete == true
4. rigor_checkpoint_passed == true (20 frameworks validated)
5. verification_passed == true (anti-hallucination, core checklist)
6. quality_checks_passed == true (integrity + legal)
7. All positions steelmanned
8. No unexplored contradictions
```

**If ANY gate fails → generate tasks to address → loop.**

---

## Rigor Checkpoint Rules

Before termination, validate against ALL 20 frameworks:

1. Follow the Money
2. Follow the Silence
3. Follow the Timeline
4. Follow the Documents
5. Follow the Contradictions
6. Follow the Relationships
7. Stakeholder Mapping
8. Network Analysis
9. Means/Motive/Opportunity
10. Competing Hypotheses
11. Assumptions Check
12. Pattern Analysis
13. Counterfactual
14. Pre-Mortem
15. Cognitive Bias Check
16. Uncomfortable Questions
17. Second-Order Effects
18. Meta Questions
19. 5 Whys (Root Cause)
20. Sense-Making

Each framework must be: ✓ Addressed (cite task/finding) | N/A (explain why) | ✗ Gap (generate task)

**Cannot pass rigor checkpoint with unexplained gaps.**

---

## Adversarial Pass Rules

After initial task generation, run adversarial review:

1. For each major claim: What would DISPROVE it?
2. Strongest argument for unexplored positions?
3. What assumptions are EMBEDDED in these tasks?
4. What evidence would CHANGE our conclusions?
5. What would the SUBJECT refuse to answer?
6. Who BENEFITS from us not investigating something?

Generate counter-tasks for each gap identified.

---

## Curiosity Requirements

Every task generation cycle MUST include curiosity check:

```
1. What would a MORE curious investigator ask?
2. What's the most important thing we DON'T know?
3. What would SURPRISE us if true?
4. Who ELSE should we be talking to/about?
5. What CONNECTIONS haven't we explored?
```

**Generate at least 2 curiosity tasks per cycle.**

---

## OSINT Source Knowledge

Investigation agents have OSINT knowledge embedded directly—no manual command exists.

| Entity Type | Sources Agents Know |
|-------------|---------------------|
| Person | OpenCorporates, courts, OpenSanctions, ICIJ, campaign finance, property |
| Corporation | SEC EDGAR, State SOS, OpenCorporates, USAspending, courts, GLEIF |
| Nonprofit | ProPublica 990s, Candid, IRS Tax Exempt, state charity registration |
| Government | USAspending, GAO/OIG reports, FOIA libraries, Federal Register |

Full reference: `framework/data-sources.md`

**The LLM knows domain knowledge.** Tasks generate specific sources relevant to THIS case—not generic templates.

---

## Termination Signals

**You ARE likely done when:**
- Same sources appear across all research engines
- New task generation yields mostly duplicates
- Rigor checkpoint finds all frameworks ✓ or N/A
- Coverage metrics at thresholds
- All 8 termination gates pass

**You are NOT done because:**
- You've completed many iterations
- It "feels" complete
- Most gates are passing

**When uncertain:** Run one more task generation cycle. If no new tasks emerge, you're done.

---

## summary.md Standards

**summary.md is THE DELIVERABLE — a polished final product.**

| Do | Don't |
|----|-------|
| Rewrite completely each update | Append incrementally |
| Smooth narrative flow | "Additionally found...", "We also discovered..." |
| Self-contained with all sources | Require external context |
| Professional journalism quality | Working document artifacts |

**The test:** Could you hand this to a journalist or executive right now?

---

## Anti-Gaming Rules

- Do NOT skip verification because "it's obviously done"
- Do NOT claim saturation to avoid more iterations
- Do NOT cherry-pick which claims to fact-check
- Do NOT ignore alternative theories because they're "obviously false"
- Do NOT give benefit of the doubt on gaps — if it's PARTIAL, it's not YES
- Do NOT skip adversarial pass because tasks "seem comprehensive"
- Do NOT bypass rigor checkpoint because "we've covered everything"
- Do NOT lower coverage thresholds because "90% is close enough"
